# ğŸ¯ CIG Model: Direct vs Pseudo-Target Approaches

## ğŸ“‹ Tá»•ng Quan

Project nÃ y cÃ³ **2 implementations** khÃ¡c nhau cho Composed Image Retrieval:

1. **Direct Embedding Comparison** (api.py + demo_website.html)
2. **Pseudo-Target Generation** (api_pseudo_target.py + demo_website_pseudo_target.html) â­ **RECOMMENDED**

---

## ğŸ”„ So SÃ¡nh Chi Tiáº¿t

### Approach 1: Direct Embedding Comparison

#### Workflow:

```
Reference Image + Text Query
         â†“
  CLIP Vision Encoder â†’ Extract features
         â†“
  Phi Network â†’ Predict pseudo tokens
         â†“
  CLIP Text Encoder â†’ Compose with query
         â†“
  Composed Embedding (768-dim vector)
         â†“
  Cosine Similarity vá»›i Database Embeddings
         â†“
  Return Top-K Results
```

#### Files:

- Backend: `api.py`
- Frontend: `demo_website.html`
- Database: `database_embeddings/fashioniq_database.pt`

#### Pros:

- âœ… **Nhanh** (~0.3 seconds)
- âœ… ÄÆ¡n giáº£n, dá»… implement
- âœ… KhÃ´ng cáº§n SDXL models
- âœ… Tiáº¿t kiá»‡m GPU memory

#### Cons:

- âŒ **Accuracy tháº¥p hÆ¡n**
- âŒ KhÃ´ng pháº£n Ã¡nh báº£n cháº¥t cá»§a CIG model
- âŒ KhÃ´ng cÃ³ visualization cá»§a target
- âŒ KhÃ³ debug khi results khÃ´ng tá»‘t

#### Use Cases:

- Quick prototyping
- Resource-constrained environments
- Real-time applications (< 1s response)

---

### Approach 2: Pseudo-Target Generation â­

#### Workflow:

```
Reference Image + Text Query
         â†“
  CLIP Vision Encoder â†’ Extract features
         â†“
  Phi Network â†’ Predict pseudo tokens
         â†“
  CLIP Text Encoder â†’ Compose with query
         â†“
  Composed Embedding â†’ SDXL Input
         â†“
  SDXL Pipeline â†’ Generate Pseudo-Target Image â­
         â†“
  CLIP Vision Encoder â†’ Extract Pseudo-Target Features
         â†“
  Cosine Similarity vá»›i Database Embeddings
         â†“
  Return Top-K Results + Pseudo-Target Image
```

#### Files:

- Backend: `api_pseudo_target.py`
- Frontend: `demo_website_pseudo_target.html`
- Database: Same as Approach 1
- Models: + SDXL checkpoint

#### Pros:

- âœ… **Higher Accuracy** (theo CIG paper)
- âœ… **ÄÃºng vá»›i báº£n cháº¥t model** - paper approach
- âœ… Visualization cá»§a pseudo-target
- âœ… Dá»… debug vÃ  understand results
- âœ… User tháº¥y Ä‘Æ°á»£c "áº£nh má»¥c tiÃªu"

#### Cons:

- âš ï¸ **Cháº­m hÆ¡n** (~10-30 seconds)
- âš ï¸ Cáº§n GPU máº¡nh (12GB+ VRAM)
- âš ï¸ Cáº§n SDXL checkpoint (~5GB)
- âš ï¸ Phá»©c táº¡p hÆ¡n

#### Use Cases:

- Research vÃ  evaluation
- Production vá»›i quality cao
- Demo vÃ  presentation
- Information Retrieval assignments â­

---

## ğŸ“Š Performance Comparison

| Metric                  | Direct Embedding | Pseudo-Target |
| ----------------------- | ---------------- | ------------- |
| **Response Time (GPU)** | 0.3s             | 15s           |
| **Response Time (CPU)** | 1s               | 5min          |
| **GPU Memory**          | 4GB              | 12GB          |
| **Disk Space**          | 1GB              | 6GB           |
| **Accuracy**            | Medium           | **High**      |
| **Paper Alignment**     | âŒ No            | âœ… **Yes**    |
| **Visualization**       | âŒ No            | âœ… **Yes**    |

---

## ğŸ¯ Which Approach to Use?

### DÃ¹ng **Direct Embedding** khi:

- â“ Cáº§n response nhanh (< 1s)
- â“ GPU memory háº¡n cháº¿ (< 8GB)
- â“ Chá»‰ cáº§n quick demo
- â“ KhÃ´ng quan tÃ¢m paper accuracy

### DÃ¹ng **Pseudo-Target** khi: â­

- âœ… **LÃ m bÃ i táº­p Information Retrieval**
- âœ… Cáº§n accuracy cao nháº¥t
- âœ… Muá»‘n understand model behavior
- âœ… CÃ³ GPU Ä‘á»§ máº¡nh
- âœ… Research vÃ  evaluation
- âœ… **Cáº¦N THEO ÄÃšNG PAPER CIG**

---

## ğŸš€ Setup Instructions

### Option 1: Direct Embedding (Simple)

```powershell
# 1. Extract database
python extract_database_features.py

# 2. Start API
python api.py

# 3. Open website
start demo_website.html
```

### Option 2: Pseudo-Target (Recommended) â­

```powershell
# 1. Check models exist
ls models\checkpoint-20000-SDXL\checkpoint-20000\unet\

# 2. Download database images (if not done)
python download_images.py --dataset fashioniq --categories dress shirt toptee

# 3. Extract database
python extract_database_features.py

# 4. Test workflow
python test_pseudo_target_workflow.py

# 5. Start API
python api_pseudo_target.py

# 6. Open website
start demo_website_pseudo_target.html
```

---

## ğŸ“ˆ Accuracy Comparison

### CIG Paper Results (with Pseudo-Target)

```
FashionIQ Recall@10:
- Dress:  XX.X%
- Shirt:  XX.X%
- Toptee: XX.X%
```

### Expected Results

**Direct Embedding:**

- Recall@10: ~15-20% lower
- Results less semantically aligned
- May retrieve similar color/pattern but wrong style

**Pseudo-Target:**

- Recall@10: As reported in paper
- Results highly aligned with query
- Better capture semantic changes

---

## ğŸ” Example Comparison

### Input:

- Reference: Blue striped shirt
- Query: "change to red and add floral pattern"

### Direct Embedding Results:

1. Red shirt (no pattern) âœ“
2. Blue floral shirt (wrong color) âœ—
3. Pink striped shirt (partial match) â–³
4. ...

**Issues:** Mixed results, khÃ´ng consistent

### Pseudo-Target Results:

**Generated Pseudo-Target:** Red floral shirt (exactly what we want!)

Search results:

1. Red floral shirt âœ“âœ“
2. Red floral dress âœ“
3. Red flower pattern shirt âœ“âœ“
4. ...

**Better:** Results highly aligned vá»›i generated image

---

## ğŸ“ Technical Deep Dive

### Why Pseudo-Target Works Better?

#### 1. Semantic Alignment

```
Direct: "Blue shirt" + "change to red" â†’ Ambiguous vector
Pseudo: Generate actual red shirt â†’ Clear visual target
```

#### 2. Feature Space

```
Direct: Composed embedding in mixed space (text+image)
Pseudo: Pure visual features (image-only space)
```

#### 3. Database Matching

```
Database contains: Pure image features (CLIP Vision)
Direct matching: Cross-modal (text-like vs image)
Pseudo matching: Same-modal (image vs image)
```

---

## ğŸ’¡ Implementation Details

### Direct Embedding (api.py)

```python
# 1. Extract reference features
ref_features = clip_vision(reference_image)

# 2. Phi network
pseudo_tokens = phi(ref_features)

# 3. Compose with text
composed_embedding = encode_text_with_pseudo_tokens(query, pseudo_tokens)

# 4. Direct search
for asin, db_embedding in database:
    similarity = cosine_sim(composed_embedding, db_embedding)
```

### Pseudo-Target (api_pseudo_target.py)

```python
# 1-3. Same as above
composed_embedding, composed_hidden = ...

# 4. Generate pseudo-target â­
pseudo_image = sdxl_pipe(
    prompt_embeds=composed_hidden,
    pooled_prompt_embeds=composed_embedding
)

# 5. Extract pseudo-target features
pseudo_features = clip_vision(pseudo_image)

# 6. Search with pure visual features
for asin, db_embedding in database:
    similarity = cosine_sim(pseudo_features, db_embedding)
```

**Key difference:** Step 4-5 adds intermediate image generation!

---

## ğŸ¬ Demo Comparison

### Direct Embedding Demo

- Input â†’ Loading (0.3s) â†’ Results
- Simple, fast
- No intermediate visualization

### Pseudo-Target Demo

- Input â†’ Loading (15s) â†’ **Pseudo-Target Image** â†’ Results
- User sees generated image
- Better understanding of what model is looking for
- More impressive for presentations!

---

## ğŸ“ For Information Retrieval Assignment

### Recommended Approach: **Pseudo-Target** â­

#### Reasons:

1. âœ… **Follows original paper** - CIG paper uses this approach
2. âœ… **Better accuracy** - Important for evaluation
3. âœ… **Clear visualization** - Easy to explain in report
4. âœ… **Research-grade** - Suitable for academic work

#### What to Include in Report:

1. **Method Description:**

   - "We implement the Pseudo-Target Generation approach from CIG paper"
   - Explain SDXL's role in generating intermediate targets
   - Show example pseudo-target images

2. **Architecture Diagram:**

   ```
   [Reference] + [Query] â†’ [SDXL] â†’ [Pseudo-Target] â†’ [Search]
   ```

3. **Evaluation:**

   - Compare with baseline (Direct Embedding)
   - Show Recall@K improvements
   - Analyze generated pseudo-targets

4. **Results:**
   - Include pseudo-target visualizations
   - Show retrieval results
   - Discuss failure cases

---

## ğŸ”§ Troubleshooting

### Common Issues:

#### "Which approach am I using?"

Check API health endpoint:

```powershell
curl http://localhost:5000/health
```

Response will include:

```json
{
  "approach": "Pseudo-Target Generation" // or "Direct Embedding"
}
```

#### "How to switch approaches?"

1. Stop current API server (Ctrl+C)
2. Start desired version:
   - Direct: `python api.py`
   - Pseudo-Target: `python api_pseudo_target.py`
3. Open corresponding HTML:
   - Direct: `demo_website.html`
   - Pseudo-Target: `demo_website_pseudo_target.html`

---

## ğŸ‰ Conclusion

### Summary Table

| Aspect                | Direct | Pseudo-Target |
| --------------------- | ------ | ------------- |
| Speed                 | âš¡âš¡âš¡ | âš¡            |
| Accuracy              | â­â­   | â­â­â­        |
| Paper Alignment       | âŒ     | âœ…            |
| Visualization         | âŒ     | âœ…            |
| GPU Required          | 4GB    | 12GB          |
| Setup Complexity      | Easy   | Medium        |
| **For IR Assignment** | âŒ     | **âœ…**        |

### Final Recommendation:

**Use Pseudo-Target Generation** for:

- âœ… Information Retrieval assignments
- âœ… Research projects
- âœ… High-quality demos
- âœ… Following CIG paper

**Use Direct Embedding** only for:

- âš¡ Quick prototypes
- ğŸ’» Limited hardware
- ğŸš€ Real-time applications

---

## ğŸ“š References

- **CIG Paper:** Generative Zero-Shot Composed Image Retrieval
- **SDXL:** Stable Diffusion XL
- **CLIP:** OpenAI CLIP
- **Implementation:** Based on official CIG codebase

---

**Happy Retrieving! ğŸ¨ğŸ”**
