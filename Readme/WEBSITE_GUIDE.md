# ğŸŒ HÆ°á»›ng Dáº«n Setup cho Website GUI Demo

## ğŸ¯ Má»¥c ÄÃ­ch: XÃ¢y Dá»±ng Website Composed Image Retrieval

**Chá»©c nÄƒng website:**

- User upload áº£nh reference
- User nháº­p text query: "TÃ´i muá»‘n áº£nh nÃ y nhÆ°ng..."
- System tráº£ vá» list áº£nh matching tá»« database

---

## ğŸ“‹ Workflow Tá»‘i Æ¯u cho Website

### ğŸ”„ Workflow Inference (Real-time)

```
User Input
  â”œâ”€ Reference Image
  â””â”€ Text Query: "more red, sleeveless"
        â†“
   CLIP Vision Encoder (real-time)
        â†“
   Phi Network (real-time)
        â†“
   CLIP Text Encoder (real-time)
        â†“
   Composed Embedding
        â†“
   Compare vá»›i Pre-computed Database Embeddings
        â†“
   Return Top-K Similar Images (URLs)
```

### ğŸ’¾ Database Preparation (Offline - 1 láº§n duy nháº¥t)

```
All Database Images (URLs)
        â†“
   Download images (táº¡m thá»i)
        â†“
   Extract Visual Features â†’ Save embeddings
        â†“
   XÃ“A downloaded images âœ…
        â†“
   Giá»¯ láº¡i: embeddings + URLs
```

---

## ğŸš€ Setup Instructions cho Website

### Phase 1: Chuáº©n Bá»‹ Database (OFFLINE - Cháº¡y 1 láº§n)

#### Step 1: Download Database Images (Táº¡m thá»i)

```bash
python download_images.py --dataset fashioniq --categories dress shirt toptee
```

**LÆ°u Ã½:** áº¢nh nÃ y sáº½ XÃ“A sau bÆ°á»›c 2

#### Step 2: Extract Database Features

```bash
# Extract features cho Táº¤T Cáº¢ áº£nh trong database
python extract_database_features.py \
    --dataset fashioniq \
    --categories dress shirt toptee \
    --output_dir ./database_embeddings
```

**Output:**

- File: `database_embeddings/fashioniq_all.pt`
- Chá»©a: Dict mapping `asin â†’ embedding`
- Size: ~500MB cho 50k images

#### Step 3: XÃ“A Downloaded Images

```bash
# Tiáº¿t kiá»‡m disk space
rm -rf datasets/FashionIQ/images/downloaded/
```

**Káº¿t quáº£ sau Phase 1:**

```
âœ… CÃ³: database_embeddings/fashioniq_all.pt (embeddings)
âœ… CÃ³: datasets/FashionIQ/images/dress.json (URLs)
âŒ KhÃ´ng cáº§n: Downloaded images (Ä‘Ã£ xÃ³a)
```

---

### Phase 2: Web Backend API (RUNTIME)

#### Backend Architecture

```python
# api.py - Flask/FastAPI backend

from flask import Flask, request, jsonify
import torch
from PIL import Image
import clip
from phi import Phi
from transformers import CLIPTextModelWithProjection, CLIPVisionModelWithProjection

app = Flask(__name__)

# Load models khi start server (1 láº§n)
clip_model = CLIPVisionModelWithProjection.from_pretrained(...)
phi_model = Phi(...)
database_embeddings = torch.load('database_embeddings/fashioniq_all.pt')
image_urls = load_image_urls('datasets/FashionIQ/images/dress.json')

@app.route('/search', methods=['POST'])
def composed_search():
    # Nháº­n input tá»« frontend
    ref_image = request.files['image']
    text_query = request.form['query']

    # 1. Extract features tá»« reference image (real-time)
    img = Image.open(ref_image)
    img_features = clip_model(preprocess(img))

    # 2. Phi network
    pseudo_tokens = phi_model(img_features)

    # 3. Combine vá»›i text query
    text_embedding = encode_text_with_pseudo_tokens(text_query, pseudo_tokens)

    # 4. Search trong database
    similarities = compute_similarity(text_embedding, database_embeddings)
    top_k_indices = torch.topk(similarities, k=20).indices

    # 5. Return URLs (khÃ´ng cáº§n áº£nh tháº­t!)
    results = [
        {
            'url': image_urls[idx],
            'score': similarities[idx].item()
        }
        for idx in top_k_indices
    ]

    return jsonify(results)

if __name__ == '__main__':
    app.run(port=5000)
```

#### Frontend (React/Vue/HTML)

```javascript
// Frontend gá»i API
async function searchImages(referenceImage, textQuery) {
  const formData = new FormData();
  formData.append("image", referenceImage);
  formData.append("query", textQuery);

  const response = await fetch("http://localhost:5000/search", {
    method: "POST",
    body: formData,
  });

  const results = await response.json();

  // Display images tá»« URLs
  results.forEach((result) => {
    displayImage(result.url, result.score);
  });
}
```

---

## â“ FAQ: test_CIG.py CÃ“ Cáº¦N CHO WEBSITE KHÃ”NG?

### CÃ¢u tráº£ lá»i: **KHÃ”NG Báº®T BUá»˜C**

**2 Approaches:**

### Approach 1: Direct Embedding Comparison (ÄÆ¡n giáº£n hÆ¡n)

```
User Query â†’ Composed Embedding â†’ Compare Database â†’ Return URLs
```

**Æ¯u Ä‘iá»ƒm:**

- âœ… Nhanh (khÃ´ng cáº§n generate image)
- âœ… ÄÆ¡n giáº£n
- âœ… Äá»§ tá»‘t cho demo

**NhÆ°á»£c Ä‘iá»ƒm:**

- âš ï¸ Accuracy cÃ³ thá»ƒ tháº¥p hÆ¡n má»™t chÃºt

### Approach 2: Vá»›i Pseudo-Target Generation (Phá»©c táº¡p hÆ¡n)

```
User Query â†’ Composed Embedding â†’ Generate Pseudo Image (test_CIG.py)
â†’ Extract Pseudo Image Features â†’ Compare Database â†’ Return URLs
```

**Æ¯u Ä‘iá»ƒm:**

- âœ… Accuracy cao hÆ¡n (theo paper)
- âœ… CÃ³ thá»ƒ show pseudo image cho user xem

**NhÆ°á»£c Ä‘iá»ƒm:**

- âš ï¸ Cháº­m hÆ¡n (pháº£i generate image: ~3-5s)
- âš ï¸ Cáº§n GPU máº¡nh hÆ¡n
- âš ï¸ Phá»©c táº¡p hÆ¡n

**Khuyáº¿n nghá»‹:** Báº¯t Ä‘áº§u vá»›i **Approach 1**, sau Ä‘Ã³ nÃ¢ng cáº¥p lÃªn Approach 2 náº¿u cáº§n.

---

## ğŸ“¦ Files Cáº§n Thiáº¿t cho Website

### Cáº§n cÃ³:

```
âœ… models/phi_best.pt              (Phi model)
âœ… models/phi_best_giga.pt         (Phi model)
âœ… database_embeddings/*.pt        (Pre-computed embeddings)
âœ… datasets/FashionIQ/images/*.json (URLs mapping)
âœ… api.py                          (Backend code)
âœ… frontend/                       (Website code)
```

### KHÃ”NG cáº§n:

```
âŒ datasets/FashionIQ/images/downloaded/  (ÄÃ£ xÃ³a sau extract)
âŒ outputs/embeddings/                    (Chá»‰ dÃ¹ng cho test_CIG.py)
âŒ outputs/generated_images/              (Chá»‰ dÃ¹ng cho evaluation)
âŒ models/sdxl_checkpoint/                (Chá»‰ cáº§n náº¿u dÃ¹ng Approach 2)
```

---

## ğŸ’» Script Ä‘á»ƒ Táº¡o Database Embeddings

### TÃ´i sáº½ táº¡o script má»›i: `extract_database_features.py`

```python
# extract_database_features.py
"""
Extract visual features cho Táº¤T Cáº¢ áº£nh trong database
Chá»‰ cháº¡y 1 láº§n khi setup website
"""

import torch
from transformers import CLIPVisionModelWithProjection
from PIL import Image
from tqdm import tqdm
import json
import os

def extract_database_features(
    dataset_path='./datasets/FashionIQ',
    categories=['dress', 'shirt', 'toptee'],
    output_path='./database_embeddings/fashioniq_all.pt'
):
    # Load CLIP model
    model = CLIPVisionModelWithProjection.from_pretrained(
        'openai/clip-vit-large-patch14'
    ).cuda()

    database = {}  # asin â†’ embedding

    for category in categories:
        # Load URLs
        json_path = f'{dataset_path}/images/{category}.json'
        with open(json_path) as f:
            items = json.load(f)

        # Load split Ä‘á»ƒ biáº¿t images nÃ o trong database
        split_path = f'{dataset_path}/image_splits/split.{category}.test.json'
        with open(split_path) as f:
            test_asins = set(json.load(f))

        # Extract features
        for item in tqdm(items, desc=f'Extracting {category}'):
            asin = item['asin']
            if asin not in test_asins:
                continue

            # Load image
            img_path = f'{dataset_path}/images/downloaded/{category}/{asin}.jpg'
            img = Image.open(img_path).convert('RGB')

            # Extract features
            with torch.no_grad():
                features = model(preprocess(img)).image_embeds

            database[asin] = features.cpu()

    # Save
    torch.save(database, output_path)
    print(f'Saved {len(database)} embeddings to {output_path}')

if __name__ == '__main__':
    extract_database_features()
```

---

## ğŸ¬ Demo Workflow

### User Experience:

```
1. User má»Ÿ website
2. Upload áº£nh Ã¡o: [Ão tráº¯ng]
3. Nháº­p query: "more red color, without sleeves"
4. Click "Search"
   â†“
5. Backend:
   - Extract features tá»« Ã¡o tráº¯ng (0.1s)
   - Phi network (0.05s)
   - Combine vá»›i "more red..." (0.05s)
   - Search database 50k images (0.1s)
   â†“
6. Return top 20 URLs (total: ~0.3s)
7. Frontend display 20 áº£nh Ã¡o Ä‘á» khÃ´ng tay
```

**Response time:** < 0.5s (ráº¥t nhanh!)

---

## ğŸ“Š So SÃ¡nh Storage

### Náº¿u GIá»® downloaded images:

```
Downloaded images:     50 GB
Embeddings:           0.5 GB
Total:               50.5 GB
```

### Náº¿u XÃ“A downloaded images:

```
Embeddings only:     0.5 GB
URLs (JSON):         0.01 GB
Total:               0.51 GB (tiáº¿t kiá»‡m 99%!)
```

---

## ğŸ”§ Next Steps cho Báº¡n

### 1. Test Models (Hiá»‡n táº¡i)

```bash
# Test xem models cÃ³ cháº¡y Ä‘Æ°á»£c khÃ´ng
python test_inference_simple.py
```

### 2. Extract Database (1 láº§n)

```bash
# Táº¡o database embeddings
python extract_database_features.py
```

### 3. XÃ³a Images (Sau khi extract xong)

```bash
rm -rf datasets/FashionIQ/images/downloaded/
```

### 4. Build API

```bash
# Táº¡o Flask/FastAPI backend
python api.py
```

### 5. Build Frontend

```bash
# React/Vue website
npm run dev
```

---

## ğŸ’¡ TÃ³m Táº¯t

### Báº¡n Cáº¦N:

1. âœ… Extract database features (1 láº§n) â†’ `.pt` files
2. âœ… URLs mapping (cÃ³ sáºµn)
3. âœ… Backend API (real-time inference)
4. âœ… Frontend website

### Báº¡n KHÃ”NG Cáº¦N:

1. âŒ Downloaded images (xÃ³a sau extract)
2. âŒ test_CIG.py (optional, dÃ¹ng cho paper evaluation)
3. âŒ SDXL models (náº¿u dÃ¹ng Approach 1)
4. âŒ Training code

### Workflow ÄÆ¡n Giáº£n:

```
Download â†’ Extract â†’ XÃ“A images â†’ Build API â†’ Done!
```

---

Báº¡n muá»‘n tÃ´i táº¡o script `extract_database_features.py` vÃ  `api.py` máº«u khÃ´ng?
